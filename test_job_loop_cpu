#!/bin/bash
#SBATCH -q preempt
#SBATCH -A m4141
#SBATCH -C cpu
#SBATCH --time=00:20:00
#SBATCH -N 1
#SBATCH --mem=0
#SBATCH --requeue
#SBATCH --comment=6:00:00  #desired time limit
#SBATCH --signal=B:USR1@1  #sig_time (1 second) should match your checkpoint overhead time
#SBATCH --job-name=syn6_qae13_QFACTOR-RUST_attached_runtime
#SBATCH --output=./slurm_outputs/adder63__7_perf_cpu_44.txt
#SBATCH --open-mode=append

date
uname -a
module load nvidia
module load python

conda activate /global/common/software/m4141/justin_env_2
# conda activate dev_env

echo "will run  TF_CPP_MIN_LOG_LEVEL=0 XLA_PYTHON_CLIENT_PREALLOCATE=false CUDA_VISIBLE_DEVICES=0 python  ./gate_deletion_perf_measurement.py  --diff_tol_a 0 --input_qasm qae13.qasm --multistarts 32 --partitions_size 8 --print_amount_of_nodes 1 --instantiator QFACTOR-JAX --amount_of_workers -1 --amount_gpus_per_node 0 "

echo $SLURM_JOB_ID
TF_CPP_MIN_LOG_LEVEL=0 XLA_PYTHON_CLIENT_PREALLOCATE=false CUDA_VISIBLE_DEVICES=0 python ./gate_deletion_perf_measurement.py  --diff_tol_a 0 --partitions_size 7 --print_amount_of_nodes 1 --multistarts 32 --input_qasm qce23_qfactor_benchmarks/adder63.qasm --instantiator QFACTOR-RUST --blocks_to_run 29 30 31 32 33 34 35 36 37 38 39 94 95 --amount_of_workers -1 --amount_gpus_per_node 0

sleep 1


# {amount_of_workers_per_gpu}
